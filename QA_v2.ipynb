{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e05be250",
   "metadata": {},
   "source": [
    "## Improvement from QA_v1:\n",
    "### 1. Change the politeness model to the sentiment model, which is powered by Bert and works better\n",
    "\n",
    "### 2. Test more cases for completeness\n",
    "\n",
    "## Outline:\n",
    "### 1. Input transcripts and grammars\n",
    "\n",
    "### 2. Sentencizer transcripts\n",
    "\n",
    "### 3. Mapping sentences to each category\n",
    "\n",
    "### 4. Calculate sentiment score for each part"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efb5aae",
   "metadata": {},
   "source": [
    "### To Do\n",
    "\n",
    "#### 1. Solve bugs in aspect matching, and add some examples to each aspect\n",
    "#### 2. Blur the boundary between different labeled classes (say the prob for classes are 75% and 80%, we can categorize it to both the classes)\n",
    "#### 3. Retrain the sentiment model\n",
    "#### 4. Using more systematic way for customized pos (spacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61d26d2d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function customized_pos.pos_postprocessor_pipe(doc)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load packages\n",
    "import nltk\n",
    "import spacy\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "# Load customized packages\n",
    "from helper.customized_pos import *\n",
    "from helper.pos_helper import *\n",
    "from helper.aspect_matching import *\n",
    "from helper.politeness_helper import *\n",
    "from helper.sentiment_helper import *\n",
    "from model_code.distilbert import *\n",
    "# Load spacy nlp model\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "# spacy version = 2.3.5 can use the following line of sentence\n",
    "# nlp.add_pipe(pos_postprocessor_pipe, name=\"pos_postprocessor\", after='tagger')\n",
    "nlp.add_pipe(\"pos_postprocessor_pipe\", after='tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5319576d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sentiment model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Souvikcmsa/SentimentAnalysisDistillBERT\")\n",
    "sentiment_model = AutoModelForSequenceClassification.from_pretrained(\"Souvikcmsa/SentimentAnalysisDistillBERT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e2e6e4",
   "metadata": {},
   "source": [
    "### Section 1: Input transcripts and grammars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6960f349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from text file\n",
    "with open (\"../data_collection/greeting_transcripts.txt\") as f:\n",
    "    greeting_transcripts_ls = f.readlines()\n",
    "with open (\"../data_collection/ending_transcripts.txt\") as f:\n",
    "    ending_transcripts_ls = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2d21b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "greeting transcripts ['ya hello good afternoon speak to nanny seah please afternoon miss nanny my name is jaguar shao and im actually calling from insurance company miss nanny good time to speak for a while this is regarding our partnership charter_plus members and as a result of that insurance company actually formulated a very special thirtieth anniversay insurance bundle right called the i thirty\\n', 'hello good afternoon just speak to miss leon michael from income ntuc free for one_or_two minutes if you are not busy okay calling behalf of your adviser xiao guo okay because we having this anniversary plan for the family i just check again you are single_or_married\\n']\n",
      "\n",
      "\n",
      "ending transcripts ['You just reconfirm with your husband whether you already have an enhanced home insurance or not if already have then we can not cover for you oh ok I will call you back tomorrow thank you bye\\n', 'So maybe if your friends or relatives or family members are interested you can call back at this number lah this number you can see from your phone lah thank you bye bye\\n']\n"
     ]
    }
   ],
   "source": [
    "print(\"greeting transcripts\", greeting_transcripts_ls)\n",
    "print(\"\\n\")\n",
    "print(\"ending transcripts\", ending_transcripts_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc98e42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "grammars = r\"\"\" \n",
    "    JP: {<JJ.*>}\n",
    "    NP: {<JP|CD>*<PRP.*|DT|NN.*>+}\n",
    "    PP: {<IN|TO|RP><NP|VB.*>} \n",
    "    VP: {<VB.*|RB.*>+<PP|NP>*}\n",
    "    Sentence: {<UH>*<JP|NP>*<MD|IN>*<VP|PP|NP|JP>+}\n",
    "    Question: {<MD|WDT|DP|WRB|><MD>*<Sentence|NP|PP|VP|JP>}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b1a742",
   "metadata": {},
   "source": [
    "### Section 2: Sentencizer transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b643552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Greeting transcripts\n",
      "Current transcript id:  0\n",
      "full result:  [['Sentence', 'ya hello good afternoon speak to nanny seah'], ['Sentence', 'please afternoon miss nanny my name is jaguar shao and'], ['Sentence', 'i m actually calling from insurance company miss nanny good time to speak for a while this is regarding our partnership charter_plus members and'], ['Sentence', 'as a result of that insurance company actually formulated a very special thirtieth anniversay insurance bundle right called the i thirty \\n']]\n",
      "\n",
      "\n",
      "only text result:  ['ya hello good afternoon speak to nanny seah', 'please afternoon miss nanny my name is jaguar shao and', 'i m actually calling from insurance company miss nanny good time to speak for a while this is regarding our partnership charter_plus members and', 'as a result of that insurance company actually formulated a very special thirtieth anniversay insurance bundle right called the i thirty \\n']\n",
      "\n",
      "\n",
      "Current transcript id:  1\n",
      "full result:  [['Sentence', 'hello good afternoon just speak to miss leon michael from income ntuc free for one_or_two minutes if you are not busy'], ['Sentence', 'okay calling behalf of your adviser xiao guo'], ['Sentence', 'okay because we having this anniversary plan for the family i just check again you are single_or_married \\n']]\n",
      "\n",
      "\n",
      "only text result:  ['hello good afternoon just speak to miss leon michael from income ntuc free for one_or_two minutes if you are not busy', 'okay calling behalf of your adviser xiao guo', 'okay because we having this anniversary plan for the family i just check again you are single_or_married \\n']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Loop to sentencizer each sentences in the transcript_ls\n",
    "text_result_dic = {}\n",
    "print(\"Greeting transcripts\")\n",
    "for i, transcripts in enumerate(greeting_transcripts_ls):\n",
    "    full_result = nlp_sentencizer(transcripts, grammars, nlp)\n",
    "    text_result = list(map(lambda x: x[1], full_result))\n",
    "    text_result_dic[i] = text_result\n",
    "    print(\"Current transcript id: \", i)\n",
    "    print(\"full result: \", full_result)\n",
    "    print(\"\\n\")\n",
    "    print(\"only text result: \", text_result)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8733c624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ending transcripts\n",
      "Current transcript id:  0\n",
      "full result:  [['Sentence', 'You just reconfirm with your husband whether you already have an enhanced home insurance or'], ['Sentence', 'not if already have then we can not cover for you oh ok I will call you back tomorrow thank you bye \\n']]\n",
      "\n",
      "\n",
      "only text result:  ['You just reconfirm with your husband whether you already have an enhanced home insurance or', 'not if already have then we can not cover for you oh ok I will call you back tomorrow thank you bye \\n']\n",
      "\n",
      "\n",
      "Current transcript id:  1\n",
      "full result:  [['Sentence', 'So maybe if your friends or relatives or family members are interested you'], ['Sentence', 'can call back at this number lah this number you'], ['Sentence', 'can see from your phone lah thank you bye bye \\n']]\n",
      "\n",
      "\n",
      "only text result:  ['So maybe if your friends or relatives or family members are interested you', 'can call back at this number lah this number you', 'can see from your phone lah thank you bye bye \\n']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ending transcripts\n",
    "text_result_dic1 = {}\n",
    "print(\"Ending transcripts\")\n",
    "for i, transcripts in enumerate(ending_transcripts_ls):\n",
    "    full_result = nlp_sentencizer(transcripts, grammars, nlp)\n",
    "    text_result = list(map(lambda x: x[1], full_result))\n",
    "    text_result_dic1[i] = text_result\n",
    "    print(\"Current transcript id: \", i)\n",
    "    print(\"full result: \", full_result)\n",
    "    print(\"\\n\")\n",
    "    print(\"only text result: \", text_result)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca5afde",
   "metadata": {},
   "source": [
    "### Section 3: Mapping sentence to each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b5b70d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Greeting result mapping\n",
      "[['ask_for_permission', 'ya hello good afternoon speak to nanny seah'], ['purpose_of_call', 'please afternoon miss nanny my name is jaguar shao and i m actually calling from insurance company miss nanny good time to speak for a while this is regarding our partnership charter_plus members and as a result of that insurance company actually formulated a very special thirtieth anniversay insurance bundle right called the i thirty \\n']]\n",
      "\n",
      "\n",
      "[['opening', 'hello good afternoon just speak to miss leon michael from income ntuc free for one_or_two minutes if you are not busy'], ['purpose_of_call', 'okay calling behalf of your adviser xiao guo'], ['ask_for_permission', 'okay because we having this anniversary plan for the family i just check again you are single_or_married \\n']]\n",
      "\n",
      "\n",
      "Ending result mapping\n",
      "[['follow-up', 'You just reconfirm with your husband whether you already have an enhanced home insurance or'], ['closing', 'not if already have then we can not cover for you oh ok I will call you back tomorrow thank you bye \\n']]\n",
      "\n",
      "\n",
      "[['follow-up', 'So maybe if your friends or relatives or family members are interested you can call back at this number lah this number you'], ['closing', 'can see from your phone lah thank you bye bye \\n']]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Looping to store mapping result to dic\n",
    "print(\"Greeting result mapping\")\n",
    "mapping_result_ls = []\n",
    "for i, text in text_result_dic.items():\n",
    "    category_ls = nlp_aspect_matching(text, nlp, 'greeting', True)\n",
    "    print(category_ls)\n",
    "    print(\"\\n\")\n",
    "    mapping_result_ls.append(category_ls)\n",
    "print(\"Ending result mapping\")\n",
    "mapping_result_ls1 = []\n",
    "for i, text in text_result_dic1.items():\n",
    "    category_ls = nlp_aspect_matching(text, nlp, 'ending', True)\n",
    "    print(category_ls)\n",
    "    print(\"\\n\")\n",
    "    mapping_result_ls1.append(category_ls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f0f60e",
   "metadata": {},
   "source": [
    "### Section 4: Calculate sentiment score for each part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "259b4c33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use updated model\n",
    "new_model = disbert_arch(sentiment_model)\n",
    "path = 'model_collection/fine_tune_disbert.pt'\n",
    "new_model.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "961b6c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Greeting part sentiments\n",
      "[['ask_for_permission', 'ya hello good afternoon speak to nanny seah', 'positive'], ['purpose_of_call', 'please afternoon miss nanny my name is jaguar shao and i m actually calling from insurance company miss nanny good time to speak for a while this is regarding our partnership charter_plus members and as a result of that insurance company actually formulated a very special thirtieth anniversay insurance bundle right called the i thirty \\n', 'neutral']]\n",
      "\n",
      "\n",
      "[['opening', 'hello good afternoon just speak to miss leon michael from income ntuc free for one_or_two minutes if you are not busy', 'neutral'], ['purpose_of_call', 'okay calling behalf of your adviser xiao guo', 'positive'], ['ask_for_permission', 'okay because we having this anniversary plan for the family i just check again you are single_or_married \\n', 'neutral']]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Greeting part sentiments\")\n",
    "for mapping_result in mapping_result_ls:\n",
    "    sentiment_ls = nlp_sentiment(mapping_result, tokenizer, new_model)\n",
    "    print(sentiment_ls)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "836840e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ending part sentiments\n",
      "[['follow-up', 'You just reconfirm with your husband whether you already have an enhanced home insurance or', 'positive'], ['closing', 'not if already have then we can not cover for you oh ok I will call you back tomorrow thank you bye \\n', 'neutral']]\n",
      "\n",
      "\n",
      "[['follow-up', 'So maybe if your friends or relatives or family members are interested you can call back at this number lah this number you', 'neutral'], ['closing', 'can see from your phone lah thank you bye bye \\n', 'positive']]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Ending part sentiments\")\n",
    "for mapping_result in mapping_result_ls1:\n",
    "    sentiment_ls = nlp_sentiment(mapping_result, tokenizer, new_model)\n",
    "    print(sentiment_ls)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56016221",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv2022",
   "language": "python",
   "name": "venv2022"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
