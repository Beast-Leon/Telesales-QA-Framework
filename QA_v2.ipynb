{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e05be250",
   "metadata": {},
   "source": [
    "## Improvement from QA_v1:\n",
    "### 1. Change the politeness model to the sentiment model, which is powered by Bert and works better\n",
    "\n",
    "### 2. Test more cases for completeness\n",
    "\n",
    "## Outline:\n",
    "### 1. Input transcripts and grammars\n",
    "\n",
    "### 2. Sentencizer transcripts\n",
    "\n",
    "### 3. Mapping sentences to each category\n",
    "\n",
    "### 4. Calculate sentiment score for each part"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efb5aae",
   "metadata": {},
   "source": [
    "### To Do\n",
    "\n",
    "#### 1. Solve bugs in aspect matching, and add some examples to each aspect\n",
    "#### 2. Blur the boundary between different labeled classes (say the prob for classes are 75% and 80%, we can categorize it to both the classes)\n",
    "#### 3. nlp_aspect_matching (bool_group = False) causes error, need debug\n",
    "#### 4. grammars pos also have error, seperating sentences in weird way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61d26d2d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function customized_pos.pos_postprocessor_pipe(doc)>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load packages\n",
    "import nltk\n",
    "import spacy\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "# Load customized packages\n",
    "from customized_pos import *\n",
    "from pos_helper import *\n",
    "from aspect_matching import *\n",
    "from politeness_helper import *\n",
    "from sentiment_helper import *\n",
    "\n",
    "# Load spacy nlp model\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "# spacy version = 2.3.5 can use the following line of sentence\n",
    "# nlp.add_pipe(pos_postprocessor_pipe, name=\"pos_postprocessor\", after='tagger')\n",
    "nlp.add_pipe(\"pos_postprocessor_pipe\", after='tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5319576d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sentiment model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Souvikcmsa/SentimentAnalysisDistillBERT\")\n",
    "sentiment_model = AutoModelForSequenceClassification.from_pretrained(\"Souvikcmsa/SentimentAnalysisDistillBERT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e2e6e4",
   "metadata": {},
   "source": [
    "### Section 1: Input transcripts and grammars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6960f349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from text file\n",
    "with open (\"data_collection/transcripts.txt\") as f:\n",
    "    transcripts_ls = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2d21b5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ya hello good afternoon speak to nanny seah please afternoon miss nanny my name is jaguar shao and im actually calling from insurance company miss nanny good time to speak for a while this is regarding our partnership charter_plus members and as a result of that insurance company actually formulated a very special thirtieth anniversay insurance bundle right called the i thirty\\n',\n",
       " 'hello good afternoon just speak to miss leon michael from income ntuc free for one_or_two minutes if you are not busy okay calling behalf of your adviser xiao guo okay because we having this anniversary plan for the family i just check again you are single_or_married\\n']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcripts_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc98e42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "grammars = r\"\"\" \n",
    "    JP: {<JJ.*>}\n",
    "    NP: {<JP|CD>*<PRP.*|DT|NN.*>+}\n",
    "    PP: {<IN|TO|RP><NP|VB.*>} \n",
    "    VP: {<VB.*|RB.*>+<JP>*}\n",
    "    VP: {<VB.*|RB.*>+<PP|NP>*}\n",
    "    Sentence: {<UH>*<JP|NP>+<MD|IN>*<VP|PP|NP>+}\n",
    "    Sentence: {<VP|PP|NP|JP>+}\n",
    "    Question: {<MD|WDT|DP|WRB|><MD>*<Sentence|NP|PP|VP|JP>}\n",
    "\"\"\"\n",
    "# grammars = r\"\"\" \n",
    "#     NP: {<PRP.*|DT|JJ|NN.*>+}\n",
    "#     PP: {<IN|TO|RP><NP|VB.*>} \n",
    "#     VP: {<VB.*|RB.*>+<PP|NP>*}\n",
    "#     Sentence: {<UH>*<NP>+<MD>*<VP|PP|NP>+}\n",
    "#     Sentence: {<PP|VP|NP>+}\n",
    "#     Question: {<MD|WDT|DP|WRB|><MD>*<Sentence|NP|PP|VP>}\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b1a742",
   "metadata": {},
   "source": [
    "### Section 2: Sentencizer transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b643552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current transcript id:  0\n",
      "full result:  [['Sentence', 'ya hello good afternoon speak to nanny seah'], ['Sentence', 'please afternoon miss nanny my name is jaguar shao and'], ['Sentence', 'i m actually calling from insurance company miss nanny good time to speak for a while this is regarding our partnership charter_plus members and'], ['Sentence', 'as a result of that insurance company actually formulated'], ['Sentence', 'a very special thirtieth anniversay insurance bundle right called the i thirty \\n']]\n",
      "\n",
      "\n",
      "only text result:  ['ya hello good afternoon speak to nanny seah', 'please afternoon miss nanny my name is jaguar shao and', 'i m actually calling from insurance company miss nanny good time to speak for a while this is regarding our partnership charter_plus members and', 'as a result of that insurance company actually formulated', 'a very special thirtieth anniversay insurance bundle right called the i thirty \\n']\n",
      "\n",
      "\n",
      "Current transcript id:  1\n",
      "full result:  [['Sentence', 'hello good afternoon just speak to miss leon michael from income ntuc'], ['Sentence', 'free for one_or_two minutes if you are not busy okay'], ['Sentence', 'calling behalf of your adviser xiao guo okay'], ['Sentence', 'because we having this anniversary plan for the family i just check again you are single_or_married \\n']]\n",
      "\n",
      "\n",
      "only text result:  ['hello good afternoon just speak to miss leon michael from income ntuc', 'free for one_or_two minutes if you are not busy okay', 'calling behalf of your adviser xiao guo okay', 'because we having this anniversary plan for the family i just check again you are single_or_married \\n']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Loop to sentencizer each sentences in the transcript_ls\n",
    "text_result_dic = {}\n",
    "for i, transcripts in enumerate(transcripts_ls):\n",
    "    full_result = nlp_sentencizer(transcripts, grammars, nlp)\n",
    "    text_result = list(map(lambda x: x[1], full_result))\n",
    "    text_result_dic[i] = text_result\n",
    "    print(\"Current transcript id: \", i)\n",
    "    print(\"full result: \", full_result)\n",
    "    print(\"\\n\")\n",
    "    print(\"only text result: \", text_result)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca5afde",
   "metadata": {},
   "source": [
    "### Section 3: Mapping sentence to each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b5b70d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['ask_for_permission', 'ya hello good afternoon speak to nanny seah'], ['purpose_of_call', 'please afternoon miss nanny my name is jaguar shao and'], ['purpose_of_call', 'i m actually calling from insurance company miss nanny good time to speak for a while this is regarding our partnership charter_plus members and'], ['purpose_of_call', 'as a result of that insurance company actually formulated'], ['purpose_of_call', 'a very special thirtieth anniversay insurance bundle right called the i thirty \\n']]\n",
      "\n",
      "\n",
      "[['opening', 'hello good afternoon just speak to miss leon michael from income ntuc'], ['ask_for_permission', 'free for one_or_two minutes if you are not busy okay'], ['purpose_of_call', 'calling behalf of your adviser xiao guo okay'], ['purpose_of_call', 'because we having this anniversary plan for the family i just check again you are single_or_married \\n']]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Looping to store mapping result to dic\n",
    "mapping_result_ls = []\n",
    "for i, text in text_result_dic.items():\n",
    "    category_ls = nlp_aspect_matching(text, nlp, 'greeting', False)\n",
    "    print(category_ls)\n",
    "    print(\"\\n\")\n",
    "    mapping_result_ls.append(category_ls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f0f60e",
   "metadata": {},
   "source": [
    "### Section 4: Calculate sentiment score for each part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98e3d67a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['ask_for_permission', 'ya hello good afternoon speak to nanny seah', 'positive'], ['purpose_of_call', 'please afternoon miss nanny my name is jaguar shao and', 'neutral'], ['purpose_of_call', 'i m actually calling from insurance company miss nanny good time to speak for a while this is regarding our partnership charter_plus members and', 'neutral'], ['purpose_of_call', 'as a result of that insurance company actually formulated', 'neutral'], ['purpose_of_call', 'a very special thirtieth anniversay insurance bundle right called the i thirty \\n', 'positive']]\n",
      "\n",
      "\n",
      "[['opening', 'hello good afternoon just speak to miss leon michael from income ntuc', 'positive'], ['ask_for_permission', 'free for one_or_two minutes if you are not busy okay', 'neutral'], ['purpose_of_call', 'calling behalf of your adviser xiao guo okay', 'neutral'], ['purpose_of_call', 'because we having this anniversary plan for the family i just check again you are single_or_married \\n', 'neutral']]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for mapping_result in mapping_result_ls:\n",
    "    sentiment_ls = nlp_sentiment(mapping_result, tokenizer, sentiment_model)\n",
    "    print(sentiment_ls)\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv2022",
   "language": "python",
   "name": "venv2022"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
