{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5c93c9a",
   "metadata": {},
   "source": [
    "## Improvement from QA_v2\n",
    "\n",
    "### 1. Use transformer model for sentence encodings\n",
    "### 2. Use fine-tuned sentiment model for sentence politeness\n",
    "### 3. Working on assigning score for each category on the QA guidelines\n",
    "### 4. Modularize and systemize the customized POS \n",
    "\n",
    "## Outline\n",
    "### 1. Input transcripts and grammars\n",
    "### 2. Sentencizer transcripts\n",
    "### 3. Mapping sentences to each category\n",
    "### 4. Calculate sentiment score for each part\n",
    "### 5. Measure passed or not for each category\n",
    "\n",
    "## To Do\n",
    "### 1. Enable multi-label category mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d526c835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load packages\n",
    "import nltk\n",
    "import spacy\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import torch\n",
    "import torch.nn\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '/Users/leon/Income/python files/politeness_code')\n",
    "\n",
    "# Load customized file\n",
    "from helper.customized_pos import *\n",
    "from helper.pos_helper import *\n",
    "from helper.grammar import *\n",
    "from helper.aspect_matching import *\n",
    "from helper.sentiment_helper import *\n",
    "from helper.score_generation import *\n",
    "from model_code.distilbert import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ca2ee33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model path\n",
    "sentiment_path = \"../model_collection/sentiment_model/fine_tune_disbert.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "256cc450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "sentiment_tokenizer = AutoTokenizer.from_pretrained(\"../model_collection/sentiment_tokenizer\")\n",
    "sentiment_model = AutoModelForSequenceClassification.from_pretrained(\"../model_collection/sentiment_model/\")\n",
    "sentiment_model = disbert_arch(sentiment_model)\n",
    "sentiment_model.load_state_dict(torch.load(sentiment_path))\n",
    "\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "sentence_model = SentenceTransformer(\"../model_collection/sentence_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b711aef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add customized rules to the spacy model\n",
    "add_pos(pos_ls, nlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7375054",
   "metadata": {},
   "source": [
    "### Section1: Input transcripts and grammars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "967187f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (\"data_collection/greeting_transcripts.txt\") as f:\n",
    "    greeting_transcripts_ls = f.readlines()\n",
    "with open (\"data_collection/ending_transcripts.txt\") as f:\n",
    "    ending_transcripts_ls = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48fce55a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "greeting transcripts ['ya hello good afternoon speak to nanny seah please afternoon miss nanny my name is jaguar shao and im actually calling from insurance company miss nanny good time to speak for a while this is regarding our partnership charter plus members and as a result of that insurance company actually formulated a very special thirtieth anniversay insurance bundle right called the i thirty\\n', 'hello good afternoon just speak to miss leon michael from income ntuc free for one or two minutes if you are not busy okay calling behalf of your adviser xiao guo okay because we having this anniversary plan for the family i just check again you are single or married\\n']\n",
      "\n",
      "\n",
      "ending transcripts ['You just reconfirm with your husband whether you already have an enhanced home insurance or not if already have then we can not cover for you oh ok I will call you back tomorrow thank you bye\\n', 'So maybe if your friends or relatives or family members are interested you can call back at this number lah this number you can see from your phone lah thank you bye bye\\n']\n"
     ]
    }
   ],
   "source": [
    "print(\"greeting transcripts\", greeting_transcripts_ls)\n",
    "print(\"\\n\")\n",
    "print(\"ending transcripts\", ending_transcripts_ls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a8d86a",
   "metadata": {},
   "source": [
    "### Section2: Sentencizer transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77ba232b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Greeting transcripts\n",
      "Current transcript id:  0\n",
      "full result:  [['Sentence', 'ya hello good afternoon speak to nanny seah'], ['Sentence', 'please afternoon miss nanny my name is jaguar shao and'], ['Sentence', 'i m actually calling from insurance company miss nanny good time to speak for a while this is regarding our partnership charter plus members and'], ['Sentence', 'as a result of that insurance company actually formulated a very special thirtieth anniversay insurance bundle right called the i thirty \\n']]\n",
      "\n",
      "\n",
      "only text result:  ['ya hello good afternoon speak to nanny seah', 'please afternoon miss nanny my name is jaguar shao and', 'i m actually calling from insurance company miss nanny good time to speak for a while this is regarding our partnership charter plus members and', 'as a result of that insurance company actually formulated a very special thirtieth anniversay insurance bundle right called the i thirty \\n']\n",
      "\n",
      "\n",
      "Current transcript id:  1\n",
      "full result:  [['Sentence', 'hello good afternoon just speak to miss leon michael from income ntuc free for one or two minutes if you are not busy'], ['Sentence', 'okay calling behalf of your adviser xiao guo'], ['Sentence', 'okay because we having this anniversary plan for the family i just check again you are single or married \\n']]\n",
      "\n",
      "\n",
      "only text result:  ['hello good afternoon just speak to miss leon michael from income ntuc free for one or two minutes if you are not busy', 'okay calling behalf of your adviser xiao guo', 'okay because we having this anniversary plan for the family i just check again you are single or married \\n']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "greeting_text_ls = []\n",
    "print(\"Greeting transcripts\")\n",
    "for i, transcripts in enumerate(greeting_transcripts_ls):\n",
    "    full_result = nlp_sentencizer(transcripts, grammars, nlp)\n",
    "    text_result = list(map(lambda x: x[1], full_result))\n",
    "    greeting_text_ls.append(text_result)\n",
    "    print(\"Current transcript id: \", i)\n",
    "    print(\"full result: \", full_result)\n",
    "    print(\"\\n\")\n",
    "    print(\"only text result: \", text_result)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "336f22a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ending transcripts\n",
      "Current transcript id:  0\n",
      "full result:  [['Sentence', 'You just reconfirm with your husband whether you already have an enhanced home insurance or'], ['Sentence', 'not if already have then we can not cover for you oh ok I will call you back tomorrow thank you bye \\n']]\n",
      "\n",
      "\n",
      "only text result:  ['You just reconfirm with your husband whether you already have an enhanced home insurance or', 'not if already have then we can not cover for you oh ok I will call you back tomorrow thank you bye \\n']\n",
      "\n",
      "\n",
      "Current transcript id:  1\n",
      "full result:  [['Sentence', 'So maybe if your friends or relatives or family members are interested you'], ['Sentence', 'can call back at this number lah this number you'], ['Sentence', 'can see from your phone lah thank you bye bye \\n']]\n",
      "\n",
      "\n",
      "only text result:  ['So maybe if your friends or relatives or family members are interested you', 'can call back at this number lah this number you', 'can see from your phone lah thank you bye bye \\n']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ending_text_ls = []\n",
    "print(\"Ending transcripts\")\n",
    "for i, transcripts in enumerate(ending_transcripts_ls):\n",
    "    full_result = nlp_sentencizer(transcripts, grammars, nlp)\n",
    "    text_result = list(map(lambda x: x[1], full_result))\n",
    "    ending_text_ls.append(text_result)\n",
    "    print(\"Current transcript id: \", i)\n",
    "    print(\"full result: \", full_result)\n",
    "    print(\"\\n\")\n",
    "    print(\"only text result: \", text_result)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f4c7d1",
   "metadata": {},
   "source": [
    "### Section3: Mapping sentence to each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0ddcabc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Greeting result mapping\n",
      "[['opening', 'ya hello good afternoon speak to nanny seah'], ['no_matching', 'please afternoon miss nanny my name is jaguar shao and'], ['purpose_of_call', 'i m actually calling from insurance company miss nanny good time to speak for a while this is regarding our partnership charter plus members and as a result of that insurance company actually formulated a very special thirtieth anniversay insurance bundle right called the i thirty \\n']]\n",
      "\n",
      "\n",
      "[['opening', 'hello good afternoon just speak to miss leon michael from income ntuc free for one or two minutes if you are not busy'], ['no_matching', 'okay calling behalf of your adviser xiao guo'], ['purpose_of_call', 'okay because we having this anniversary plan for the family i just check again you are single or married \\n']]\n",
      "\n",
      "\n",
      "Ending result mapping\n",
      "[['no_matching', 'You just reconfirm with your husband whether you already have an enhanced home insurance or'], ['follow-up', 'not if already have then we can not cover for you oh ok I will call you back tomorrow thank you bye \\n']]\n",
      "\n",
      "\n",
      "[['no_matching', 'So maybe if your friends or relatives or family members are interested you'], ['follow-up', 'can call back at this number lah this number you'], ['closing', 'can see from your phone lah thank you bye bye \\n']]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Looping to store mapping result to dic\n",
    "print(\"Greeting result mapping\")\n",
    "mapping_greeting = []\n",
    "for i, text in enumerate(greeting_text_ls):\n",
    "    category_ls = nlp_aspect_matching(text, sentence_model, 'greeting', True, 0.4)\n",
    "    print(category_ls)\n",
    "    print(\"\\n\")\n",
    "    mapping_greeting.append(category_ls)\n",
    "print(\"Ending result mapping\")\n",
    "mapping_ending = []\n",
    "for i, text in enumerate(ending_text_ls):\n",
    "    category_ls = nlp_aspect_matching(text, sentence_model, 'ending', True, 0.4)\n",
    "    print(category_ls)\n",
    "    print(\"\\n\")\n",
    "    mapping_ending.append(category_ls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e72a70",
   "metadata": {},
   "source": [
    "### Section4: Calculate sentiment score for each part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7eea951b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Greeting part sentiments\n",
      "[['opening', 'ya hello good afternoon speak to nanny seah', 'positive'], ['no_matching', 'please afternoon miss nanny my name is jaguar shao and', 'neutral'], ['purpose_of_call', 'i m actually calling from insurance company miss nanny good time to speak for a while this is regarding our partnership charter plus members and as a result of that insurance company actually formulated a very special thirtieth anniversay insurance bundle right called the i thirty \\n', 'neutral']]\n",
      "\n",
      "\n",
      "[['opening', 'hello good afternoon just speak to miss leon michael from income ntuc free for one or two minutes if you are not busy', 'neutral'], ['no_matching', 'okay calling behalf of your adviser xiao guo', 'positive'], ['purpose_of_call', 'okay because we having this anniversary plan for the family i just check again you are single or married \\n', 'neutral']]\n",
      "\n",
      "\n",
      "Ending part sentiments\n",
      "[['no_matching', 'You just reconfirm with your husband whether you already have an enhanced home insurance or', 'positive'], ['follow-up', 'not if already have then we can not cover for you oh ok I will call you back tomorrow thank you bye \\n', 'neutral']]\n",
      "\n",
      "\n",
      "[['no_matching', 'So maybe if your friends or relatives or family members are interested you', 'positive'], ['follow-up', 'can call back at this number lah this number you', 'neutral'], ['closing', 'can see from your phone lah thank you bye bye \\n', 'positive']]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Greeting part sentiments\")\n",
    "sentiment_greeting = []\n",
    "for mapping in mapping_greeting:\n",
    "    sentiment_ls = nlp_sentiment(mapping, sentiment_tokenizer, sentiment_model)\n",
    "    sentiment_greeting.append(sentiment_ls)\n",
    "    print(sentiment_ls)\n",
    "    print(\"\\n\")\n",
    "\n",
    "print(\"Ending part sentiments\")\n",
    "sentiment_ending = []\n",
    "for mapping in mapping_ending:\n",
    "    sentiment_ls = nlp_sentiment(mapping, sentiment_tokenizer, sentiment_model)\n",
    "    sentiment_ending.append(sentiment_ls)\n",
    "    print(sentiment_ls)\n",
    "    print(\"\\n\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40280b63",
   "metadata": {},
   "source": [
    "### Section5: Measure passed or not for each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1535427e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Greeting result\n",
      "{'sentence_collection': {'opening': [['ya hello good afternoon speak to nanny seah', 'positive']], 'no_matching': [['please afternoon miss nanny my name is jaguar shao and', 'neutral']], 'purpose_of_call': [['i m actually calling from insurance company miss nanny good time to speak for a while this is regarding our partnership charter plus members and as a result of that insurance company actually formulated a very special thirtieth anniversay insurance bundle right called the i thirty \\n', 'neutral']]}, 'score_collection': {'opening': True, 'purpose_of_call': True, 'ask_for_permission': False}}\n",
      "\n",
      "\n",
      "{'sentence_collection': {'opening': [['hello good afternoon just speak to miss leon michael from income ntuc free for one or two minutes if you are not busy', 'neutral']], 'no_matching': [['okay calling behalf of your adviser xiao guo', 'positive']], 'purpose_of_call': [['okay because we having this anniversary plan for the family i just check again you are single or married \\n', 'neutral']]}, 'score_collection': {'opening': True, 'purpose_of_call': True, 'ask_for_permission': False}}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "greeting_result_ls = []\n",
    "print(\"Greeting result\")\n",
    "for result in sentiment_greeting:\n",
    "    result_dic = result_reformat(result, greeting_lexicons)\n",
    "    score_dic = assign_score(result_dic, greeting_lexicons)\n",
    "    temp_dic = {\"sentence_collection\": result_dic, \"score_collection\": score_dic}\n",
    "    print(temp_dic)\n",
    "    print(\"\\n\")\n",
    "    greeting_result_ls.append(temp_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b2f82692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ending result\n",
      "{'sentence_collection': {'no_matching': [['You just reconfirm with your husband whether you already have an enhanced home insurance or', 'positive']], 'follow-up': [['not if already have then we can not cover for you oh ok I will call you back tomorrow thank you bye \\n', 'neutral']]}, 'score_collection': {'closing': False, 'data_enrichment': False, 'follow-up': True}}\n",
      "\n",
      "\n",
      "{'sentence_collection': {'no_matching': [['So maybe if your friends or relatives or family members are interested you', 'positive']], 'follow-up': [['can call back at this number lah this number you', 'neutral']], 'closing': [['can see from your phone lah thank you bye bye \\n', 'positive']]}, 'score_collection': {'closing': True, 'data_enrichment': False, 'follow-up': True}}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ending_result_ls = []\n",
    "print(\"Ending result\")\n",
    "for result in sentiment_ending:\n",
    "    result_dic = result_reformat(result, ending_lexicons)\n",
    "    score_dic = assign_score(result_dic, ending_lexicons)\n",
    "    temp_dic = {\"sentence_collection\": result_dic, \"score_collection\": score_dic}\n",
    "    print(temp_dic)\n",
    "    print(\"\\n\")\n",
    "    ending_result_ls.append(temp_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57aa12fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv2022",
   "language": "python",
   "name": "venv2022"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
